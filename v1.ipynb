{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def scrape(path: str) -> str:\n",
    "    try:\n",
    "        full_url = f\"https://r.jina.ai/{path}\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(full_url, timeout=10) as response:\n",
    "                response.raise_for_status()\n",
    "                return await response.text()\n",
    "    except aiohttp.ClientError as e:\n",
    "        print(f\"Error occurred while fetching {full_url}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "if openai_api_key is None:\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY is missing in environment variables.\")\n",
    "\n",
    "def openai_client():\n",
    "    return AsyncOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def llm(query: str) -> str:\n",
    "    prompt = f\"{query}\"\n",
    "    try:\n",
    "        chat_completion = await openai_client().chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ])\n",
    "        return chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating LLM response: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"Failed to generate response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def split_input_prompt(input: str) -> str:\n",
    "    instruction = \"\"\"\n",
    "    You are given an input string containing a URL and a question. Your task is to split the input into two parts: the URL and the question.\n",
    "    The extracted question must retain full context and meaning from the original input. Ensure that no relevant information from the question is removed.\n",
    "    The URL must always start with \"https://\". If the input does not include \"https://\" explicitly, prepend it to the extracted URL.\n",
    "\n",
    "    Return the result in the following format, with no additional text or markdown:\n",
    "\n",
    "    URL: <extracted_url>\n",
    "    Question: <extracted_question>\n",
    "\n",
    "    For example:\n",
    "    Input: \"Visit https://example.com and find out What is the purpose of this website?\"\n",
    "    Output:\n",
    "    URL: https://example.com\n",
    "    Question: What is the purpose of this website?\n",
    "\n",
    "    Input: \"What does https://evergrowadvisors.com/ do?\"\n",
    "    Output:\n",
    "    URL: https://evergrowadvisors.com\n",
    "    Question: What does evergrowadvisors do?\n",
    "\n",
    "    Input: \"is quicksell.co a product based company?\"\n",
    "    Output:\n",
    "    URL: https://quicksell.co\n",
    "    Question: Is quicksell a product based company?\n",
    "\n",
    "    Strictly ensure the format matches the example provided, with the extracted URL and question on separate lines prefixed by \"URL:\" and \"Question:\".\n",
    "    \"\"\"\n",
    "    prompt = f\"{instruction}\\nInput: \\\"{input}\\\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "async def extract_url_and_query(response: str):\n",
    "    match = re.search(r\"URL: (.+)\\nQuestion: (.+)\", response)\n",
    "    if match:\n",
    "        base_url = match.group(1).strip()\n",
    "        query = match.group(2).strip()\n",
    "        return base_url, query\n",
    "    else:\n",
    "        raise ValueError(\"Response format does not match the expected pattern.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_prompt(scraped_content: str, query: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Answer the query '{query}' based upon the scraped content '{scraped_content}'.\n",
    "    Return the answer. If you don't find the answer in the scraped content, return the next URL to scrape \n",
    "    and go into it to find the answer based on the text of the hyperlink and text around the link.\n",
    "\n",
    "    Format of response:\n",
    "    Answer: <your_answer>\n",
    "    Next URL: <next_url or None>\n",
    "\n",
    "    If you found the answer, set 'Next URL' to 'None'.\n",
    "    If you didn't find the answer, set 'Answer' to 'Not Found'.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_response(response: str) -> tuple:\n",
    "    match = re.search(r\"Answer: (.+)\\nNext URL: (.+)\", response)\n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "        next_url = match.group(2).strip()\n",
    "        return answer, next_url\n",
    "    raise ValueError(\"Response format does not match the expected pattern.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"AI\")\n",
    "\n",
    "async def scrape_and_query(base_url: str, query: str) -> Optional[str]:\n",
    "    current_url = base_url\n",
    "    attempt_count = 0\n",
    "\n",
    "    while current_url:\n",
    "        attempt_count += 1\n",
    "        logger.info(\"-\" * 100)\n",
    "        logger.info(f\"Attempt {attempt_count}: Scraping content from URL: {current_url}\")\n",
    "\n",
    "        scraped_content = await scrape(current_url)\n",
    "        if not scraped_content:\n",
    "            logger.error(f\"Failed to scrape content from {current_url}. Ending process.\")\n",
    "            break\n",
    "\n",
    "        logger.info(\"Successfully scraped content. Generating LLM prompt...\")\n",
    "\n",
    "        prompt = await generate_prompt(scraped_content, query)\n",
    "\n",
    "        try:\n",
    "            logger.info(\"Sending prompt to LLM...\")\n",
    "            response = await llm(prompt)\n",
    "            answer, next_url = await parse_response(response)\n",
    "\n",
    "            logger.info(f\"Response from LLM:\\nAnswer: {answer}\\nNext URL: {next_url}\")\n",
    "\n",
    "            if next_url.lower() == \"none\":\n",
    "                if answer != \"Not Found\":\n",
    "                    logger.info(\"Answer successfully found. Ending process.\")\n",
    "                    return answer\n",
    "                else:\n",
    "                    logger.warning(\"Answer not found in content. Ending process.\")\n",
    "                    return \"Answer not found in content.\"\n",
    "\n",
    "            if answer == \"Not Found\":\n",
    "                logger.warning(f\"Answer not found. Navigating to next URL: {next_url}\\n\")\n",
    "                current_url = next_url\n",
    "            else:\n",
    "                logger.info(\"Answer successfully found. Stopping search.\")\n",
    "                current_url = None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occurred during LLM query or Parsing: {e}\")\n",
    "            break\n",
    "\n",
    "    logger.info(\"No answer found after multiple attempts.\")\n",
    "    return \"No answer found after multiple attempts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AI:----------------------------------------------------------------------------------------------------\n",
      "INFO:AI:Attempt 1: Scraping content from URL: https://iitr.ac.in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base URL: https://iitr.ac.in\n",
      "Query: Find the email of Head of Department of Computer Science and Engineering.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AI:Successfully scraped content. Generating LLM prompt...\n",
      "INFO:AI:Sending prompt to LLM...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AI:Response from LLM:\n",
      "Answer: Not Found\n",
      "Next URL: https://iitr.ac.in/Departments/index.html\n",
      "WARNING:AI:Answer not found. Navigating to next URL: https://iitr.ac.in/Departments/index.html\n",
      "\n",
      "INFO:AI:----------------------------------------------------------------------------------------------------\n",
      "INFO:AI:Attempt 2: Scraping content from URL: https://iitr.ac.in/Departments/index.html\n",
      "INFO:AI:Successfully scraped content. Generating LLM prompt...\n",
      "INFO:AI:Sending prompt to LLM...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AI:Response from LLM:\n",
      "Answer: Not Found\n",
      "Next URL: https://iitr.ac.in/Departments/Computer%20Science%20and%20Engineering%20Department/index.html\n",
      "WARNING:AI:Answer not found. Navigating to next URL: https://iitr.ac.in/Departments/Computer%20Science%20and%20Engineering%20Department/index.html\n",
      "\n",
      "INFO:AI:----------------------------------------------------------------------------------------------------\n",
      "INFO:AI:Attempt 3: Scraping content from URL: https://iitr.ac.in/Departments/Computer%20Science%20and%20Engineering%20Department/index.html\n",
      "INFO:AI:Successfully scraped content. Generating LLM prompt...\n",
      "INFO:AI:Sending prompt to LLM...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AI:Response from LLM:\n",
      "Answer: csed@iitr.ac.in\n",
      "Next URL: None\n",
      "INFO:AI:Answer successfully found. Ending process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer: csed@iitr.ac.in\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    input = \"visit iitr.ac.in and find the email of Head of Department of Computer Science and Engineering\"\n",
    "    try:\n",
    "        split_prompt = await split_input_prompt(input)\n",
    "        split_response = await llm(split_prompt)\n",
    "        \n",
    "        base_url, query = await extract_url_and_query(split_response)\n",
    "        print(\"Base URL:\", base_url)\n",
    "        print(\"Query:\", query)\n",
    "                \n",
    "        final_answer = await scrape_and_query(base_url, query)\n",
    "        print(\"\\nFinal Answer:\", final_answer)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(\"Error during URL or query extraction:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"An unexpected error occurred:\", e)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
