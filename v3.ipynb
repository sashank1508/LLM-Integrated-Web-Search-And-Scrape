{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def scrape(path: str) -> str:\n",
    "    try:\n",
    "        full_url = f\"https://r.jina.ai/{path}\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(full_url, timeout=10) as response:\n",
    "                response.raise_for_status()\n",
    "                return await response.text()\n",
    "    except aiohttp.ClientError as e:\n",
    "        print(f\"Error occurred while fetching {full_url}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "if openai_api_key is None:\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY is missing in environment variables.\")\n",
    "\n",
    "def openai_client():\n",
    "    return AsyncOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def llm(query: str) -> str:\n",
    "    prompt = f\"{query}\"\n",
    "    try:\n",
    "        chat_completion = await openai_client().chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ])\n",
    "        return chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating LLM response: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"Failed to generate response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def split_input_prompt(input: str) -> str:\n",
    "    instruction = \"\"\"\n",
    "    You are given an input string containing a URL and a question. Your task is to split the input into two parts: the URL and the question.\n",
    "    The extracted question must retain full context and meaning from the original input. Ensure that no relevant information from the question is removed.\n",
    "    The URL must always start with \"https://\". If the input does not include \"https://\" explicitly, prepend it to the extracted URL.\n",
    "    If no URL is present in the input, provide the query to search for the URL.\n",
    "\n",
    "    Return the result in the following format, with no additional text or markdown:\n",
    "\n",
    "    URL: <extracted_url or query_to_search>\n",
    "    Question: <extracted_question>\n",
    "\n",
    "    For example:\n",
    "    Input: \"Visit https://example.com and find out What is the purpose of this website?\"\n",
    "    Output:\n",
    "    URL: https://example.com\n",
    "    Question: What is the purpose of this website?\n",
    "\n",
    "    Input: \"What does https://evergrowadvisors.com/ do?\"\n",
    "    Output:\n",
    "    URL: https://evergrowadvisors.com\n",
    "    Question: What does evergrowadvisors do?\n",
    "\n",
    "    Input: \"What does Evergrow Advisors do?\"\n",
    "    Output: URL: Evergrow Advisors\n",
    "    Question: What does Evergrow Advisors do?\n",
    "\n",
    "    Input: \"is quicksell.co a product based company?\"\n",
    "    Output:\n",
    "    URL: https://quicksell.co\n",
    "    Question: Is quicksell a product based company?\n",
    "\n",
    "    Strictly ensure the format matches the example provided, with the extracted URL and question on separate lines prefixed by \"URL:\" and \"Question:\".\n",
    "    \"\"\"\n",
    "    prompt = f\"{instruction}\\nInput: \\\"{input}\\\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "async def extract_url_and_query(response: str):\n",
    "    match = re.search(r\"URL: (.+)\\nQuestion: (.+)\", response)\n",
    "    if match:\n",
    "        base_url = match.group(1).strip()\n",
    "        query = match.group(2).strip()\n",
    "        return base_url, query\n",
    "    else:\n",
    "        raise ValueError(\"Response format does not match the expected pattern.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "async def google_search(query: str, num_results: int = 10) -> list:\n",
    "    results = search(query, num_results=num_results, lang=\"en\")\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_prompt(scraped_content: str, query: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the scraped content provided below, answer the query strictly following the format outlined. \n",
    "\n",
    "    Query: '{query}'\n",
    "    Scraped Content: '{scraped_content}'\n",
    "    \n",
    "    Return the answer. If you don't find the answer in the scraped content, return the next URL to scrape \n",
    "    and go into it to find the answer based on the text of the hyperlink and text around the link.\n",
    "\n",
    "    Instructions:\n",
    "    1. Return the response in plain text only. Do not use any special formatting such as markdowns or bullet points.\n",
    "    2. The response must strictly follow this format:\n",
    "       Answer: <your_answer>\n",
    "       Next URL: <next_url or None>\n",
    "    3. If the answer is found in the scraped content, provide it under 'Answer' and set 'Next URL' to 'None'.\n",
    "    4. If the answer is not found in the scraped content but there is a next URL to explore, set 'Answer' to 'Not Found' and provide the 'Next URL' to explore further.\n",
    "    5. If the answer is not found in the scraped content and there is no URL to go next, set:\n",
    "       Answer: Not Found\n",
    "       Next URL: None\n",
    "    6. The response must adhere strictly to the format without any deviation.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_response(response: str) -> tuple:\n",
    "    match = re.search(r\"Answer: (.+)\\nNext URL: (.+)\", response)\n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "        next_url = match.group(2).strip()\n",
    "        return answer, next_url\n",
    "    raise ValueError(\"Response format does not match the expected pattern.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_and_query(google_results: list, query: str, skip_urls: list) -> Optional[str]:\n",
    "    attempt_count = 0\n",
    "    visited_urls = set()\n",
    "\n",
    "    for current_url in google_results:\n",
    "\n",
    "        while current_url:\n",
    "            if current_url in visited_urls:\n",
    "                logger.warning(f\"URL {current_url} Has Already Been Visited. Skipping...\\n\")\n",
    "                break\n",
    "\n",
    "            if current_url in skip_urls:\n",
    "                logger.warning(f\"URL {current_url} Is In The Skip List. Skipping...\\n\")\n",
    "                break\n",
    "\n",
    "            attempt_count += 1\n",
    "            logger.info(\"-\" * 100)\n",
    "            logger.info(f\"Attempt {attempt_count}:\\nScraping Content From URL: {current_url}\")\n",
    "\n",
    "            visited_urls.add(current_url)\n",
    "\n",
    "            scraped_content = await scrape(current_url)\n",
    "            if not scraped_content:\n",
    "                logger.error(f\"Failed To Scrape Content From {current_url}. Trying Next URL.\")\n",
    "                break\n",
    "\n",
    "            logger.info(\"Successfully Scraped Content.\")\n",
    "            logger.info(\"Generating LLM prompt...\")\n",
    "\n",
    "            prompt = await generate_prompt(scraped_content, query)\n",
    "\n",
    "            try:\n",
    "                logger.info(\"Sending Prompt To LLM...\")\n",
    "                response = await llm(prompt)\n",
    "                answer, next_url = await parse_response(response)\n",
    "\n",
    "                logger.info(f\"Response From LLM:\\nAnswer: {answer}\\nNext URL: {next_url}\")\n",
    "\n",
    "                if next_url.lower() == \"none\" and answer == \"Not Found\":\n",
    "                    logger.warning(\"Answer Not Found In Content.\\nTrying Next URL In Google Results.\\n\")\n",
    "                    break\n",
    "\n",
    "                if next_url.lower() == \"none\":\n",
    "                    if answer != \"Not Found\":\n",
    "                        logger.info(\"Answer Successfully Found. Ending Process.\")\n",
    "                        return answer\n",
    "\n",
    "                if next_url == current_url:\n",
    "                    logger.warning(f\"Next URL Is The Same As The Current URL: {next_url}.\\nSkipping To Next URL In Google Results.\\n\")\n",
    "                    break\n",
    "\n",
    "                if answer == \"Not Found\" and next_url.lower() != \"none\":\n",
    "                    logger.warning(f\"Answer Not Found.\\nNavigating to next URL: {next_url}\\n\")\n",
    "                    \n",
    "                current_url = next_url\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error Occurred During LLM Query Or Parsing: {e}\\n\")\n",
    "                break\n",
    "\n",
    "    logger.info(\"No Answer Found After Attempting All Google Search Results.\")\n",
    "    return \"No Answer Found After Multiple Attempts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AI:Attempting To Find The URL Via Google Search...\n",
      "\n",
      "INFO:AI:----------------------------------------------------------------------------------------------------\n",
      "INFO:AI:Attempt 1:\n",
      "Scraping Content From URL: http://www.hpclinks.com/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base URL: HPC Links\n",
      "Query: Who is the founder of HPC Links?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AI:Successfully Scraped Content.\n",
      "INFO:AI:Generating LLM prompt...\n",
      "INFO:AI:Sending Prompt To LLM...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AI:Response From LLM:\n",
      "Answer: Not Found\n",
      "Next URL: http://www.hpclinks.com/about/index.shtml\n",
      "WARNING:AI:Answer Not Found.\n",
      "Navigating to next URL: http://www.hpclinks.com/about/index.shtml\n",
      "\n",
      "INFO:AI:----------------------------------------------------------------------------------------------------\n",
      "INFO:AI:Attempt 2:\n",
      "Scraping Content From URL: http://www.hpclinks.com/about/index.shtml\n",
      "INFO:AI:Successfully Scraped Content.\n",
      "INFO:AI:Generating LLM prompt...\n",
      "INFO:AI:Sending Prompt To LLM...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AI:Response From LLM:\n",
      "Answer: Ashwini Kumar Nanda, Ph.D.\n",
      "Next URL: None\n",
      "INFO:AI:Answer Successfully Found. Ending Process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer: Ashwini Kumar Nanda, Ph.D.\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    input = \"\"\"Who Is The Founder Of HPC Links?\"\"\"\n",
    "    skip_urls = []\n",
    "    try:\n",
    "        split_prompt = await split_input_prompt(input)\n",
    "        split_response = await llm(split_prompt)\n",
    "        \n",
    "        base_url, query = await extract_url_and_query(split_response)\n",
    "        \n",
    "        if not base_url.startswith(\"http\"):\n",
    "            logger.info(\"Attempting To Find The URL Via Google Search...\\n\")\n",
    "            google_results = await google_search(base_url, num_results=10)\n",
    "        else:\n",
    "            google_results = [base_url] + await google_search(base_url, num_results=10)\n",
    "\n",
    "        print(\"Base URL:\", base_url)\n",
    "        print(\"Query:\", query)\n",
    "                \n",
    "        final_answer = await scrape_and_query(google_results, query, skip_urls)\n",
    "        print(\"\\nFinal Answer:\", final_answer)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(\"Error During URL Or Query Extraction:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"An Unexpected Error Occurred:\", e)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
